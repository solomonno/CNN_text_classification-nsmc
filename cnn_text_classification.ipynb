{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "load data\n",
    "\"\"\"\n",
    "import json, requests\n",
    "import numpy as np\n",
    "\n",
    "data_path = 'https://raw.githubusercontent.com/KLUE-benchmark/KLUE/main/klue_benchmark/ynat-v1.1/ynat-v1.1_train.json'\n",
    "url = requests.get(data_path)\n",
    "\n",
    "dataset = np.array([['title', 'label', 'predefined_news_category']])\n",
    "\n",
    "for line in json.loads(url.text):\n",
    "    data = np.array([[line['title'], line['label'], line['predefined_news_category']]])\n",
    "    dataset = np.concatenate((dataset, data), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "tokenizer\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "dataframe = pd.DataFrame(dataset[1:], columns=dataset[0]) # 9108 samples\n",
    "if dataframe.isnull().values.any():\n",
    "    dataframe.dropna_()\n",
    "\n",
    "# tokenizer: 띄어쓰기 기준 \n",
    "tokenizer = [word.split(' ') for word in dataframe['title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "vocab\n",
    "\"\"\"\n",
    "counter = Counter(sum(tokenizer, [])) # 31851 words\n",
    "vocab_sorted = sorted(counter.items(), key = lambda x:x[1], reverse = True)\n",
    "\n",
    "vocab = {}\n",
    "for i, (word, frequency) in enumerate(vocab_sorted):\n",
    "    vocab[word] = i+1\n",
    "vocab['OOV'] = len(vocab) + 1\n",
    "\n",
    "\n",
    "encoded_sentences = []\n",
    "for sentence in tokenizer:\n",
    "    encoded_sentence = []\n",
    "    for word in sentence:\n",
    "        try:\n",
    "            encoded_sentence.append(vocab[word])\n",
    "        except KeyError:\n",
    "            encoded_sentence.append(vocab['OOV'])\n",
    "    encoded_sentences.append(encoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "padding\n",
    "\"\"\"\n",
    "max_len = max(len(item) for item in encoded_sentences) # 12\n",
    "for sentence in encoded_sentences:\n",
    "    while len(sentence) < max_len:\n",
    "        sentence.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "SGNS data processing\n",
    "\"\"\"\n",
    "from itertools import permutations, product\n",
    "window_size = 5\n",
    "\n",
    "skip_gram = []\n",
    "for encoded_sentence in encoded_sentences:\n",
    "    full_permutations = list(set(permutations(encoded_sentence,2)))\n",
    "    window_permutations = []\n",
    "    for i in range(len(encoded_sentence)):\n",
    "        left = max(0, i-window_size)\n",
    "        right = min(i+window_size, max_len)+1\n",
    "        remove_i_list = encoded_sentence[left:i] + encoded_sentence[i+1:right]\n",
    "        window_permutations.append(list(product([encoded_sentence[i]], remove_i_list)))\n",
    "\n",
    "    for full_permutation in full_permutations:\n",
    "        if full_permutation in list(set(sum(window_permutations, []))):\n",
    "            skip_gram.append(list(full_permutation) + [1])\n",
    "        else:\n",
    "            skip_gram.append(list(full_permutation) + [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "embedding model-SGNS\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6e8f82fcda7f32881d23a0e095c1c6772070bdbf134f5a4709928c51b7fc2ea7"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('torch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
